import sys
import os
import argparse
import logging
import json
import time


import numpy as np
import torch
from torch.utils.data import DataLoader
from torch.autograd import Variable

sys.path.append(os.path.dirname(os.path.abspath(__file__)) + '/../../')

torch.manual_seed(0)
torch.cuda.manual_seed_all(0)

from wsi.data.wsi_producer import GridWSIPatchDataset  # noqa
from wsi.model import MODELS  # noqa


parser = argparse.ArgumentParser(description='Get the probability map of tumor'
                                 ' patch predictions given a WSI')
parser.add_argument('wsi_path', default=None, metavar='WSI_PATH', type=str,
                    help='Path to the input WSI file')
parser.add_argument('ckpt_path', default=None, metavar='CKPT_PATH', type=str,
                    help='Path to the saved ckpt file of a pytorch model')
parser.add_argument('cfg_path', default=None, metavar='CFG_PATH', type=str,
                    help='Path to the config file in json format related to'
                    ' the ckpt file')
parser.add_argument('mask_path', default=None, metavar='MASK_PATH', type=str,
                    help='Path to the tissue mask of the input WSI file')
parser.add_argument('probs_map_path', default=None, metavar='PROBS_MAP_PATH',
                    type=str, help='Path to the output probs_map numpy file')
parser.add_argument('--GPU', default='7', type=str, help='which GPU to use'
                    ', default 0')
parser.add_argument('--num_workers', default=5, type=int, help='number of '
                    'workers to use to make batch, default 5')
parser.add_argument('--eight_avg', default=0, type=int, help='if using average'
                    ' of the 8 direction predictions for each patch,'
                    ' default 0, which means disabled')


#def get_probs_map(model, dataloader):
def get_probs_map(th, total, model, dataloader):
    probs_map = np.zeros(dataloader.dataset._mask.shape)
    num_batch = len(dataloader)
    # only use the prediction of the center patch within the grid
    idx_center = dataloader.dataset._grid_size // 2

    count = 0
    time_now = time.time()
    for (data, x_mask, y_mask) in dataloader:
        data = Variable(data.cuda(async=True), volatile=True)
        output = model(data)
        # because of torch.squeeze at the end of forward in resnet.py, if the
        # len of dim_0 (batch_size) of data is 1, then output removes this dim.
        # should be fixed in resnet.py by specifying torch.squeeze(dim=2) later
        if len(output.shape) == 1:
            probs = output[idx_center].sigmoid().cpu().data.numpy().flatten()
        else:
            probs = output[:,
                           idx_center].sigmoid().cpu().data.numpy().flatten()
        probs_map[x_mask, y_mask] = probs
        count += 1
        if count%100==0:
            time_spent = time.time() - time_now
            time_now = time.time()
            logging.info(
                '{}, flip : {}, rotate : {}, Processing : {}/{}, batch : {}/{}, Run Time : {:.2f}'
                .format(
                    time.strftime("%Y-%m-%d %H:%M:%S"), dataloader.dataset._flip,
                    dataloader.dataset._rotate, th, total, count, num_batch, time_spent))

    return probs_map

'''单张tif预测'''       
#def make_dataloader(args, cfg, flip='NONE', rotate='NONE'):
#    batch_size = cfg['batch_size'] #* 2
#    num_workers = args.num_workers
#    
#    dataloader = DataLoader(
#        GridWSIPatchDataset(args.wsi_path, args.mask_path,
#                            image_size=cfg['image_size'],
#                            patch_size=cfg['patch_size'],
#                            crop_size=cfg['crop_size'], normalize=True,
#                            flip=flip, rotate=rotate),
#        batch_size=batch_size, num_workers=num_workers, drop_last=False)
#
#    return dataloader
    
'''批量tif预测'''
def make_dataloader(args, wsi_path, mask_path, cfg, flip='NONE', rotate='NONE'):
    batch_size = cfg['batch_size'] #* 2
    num_workers = args.num_workers
    
    dataloader = DataLoader(
        GridWSIPatchDataset(args.wsi_path + wsi_path, args.mask_path + mask_path,
                            image_size=cfg['image_size'],
                            patch_size=cfg['patch_size'],
                            crop_size=cfg['crop_size'], normalize=True,
                            flip=flip, rotate=rotate),
        batch_size=batch_size, num_workers=num_workers, drop_last=False)

    return dataloader


def run(args):
    os.environ["CUDA_VISIBLE_DEVICES"] = args.GPU
    logging.basicConfig(level=logging.INFO)

    with open(args.cfg_path) as f:
        cfg = json.load(f)

    if cfg['image_size'] % cfg['patch_size'] != 0:
            raise Exception('Image size / patch size != 0 : {} / {}'.
                            format(cfg['image_size'], cfg['patch_size']))

    patch_per_side = cfg['image_size'] // cfg['patch_size']
    grid_size = patch_per_side * patch_per_side

    ckpt = torch.load(args.ckpt_path)
    model = MODELS[cfg['model']](num_nodes=grid_size, use_crf=cfg['use_crf'])
    model.load_state_dict(ckpt['state_dict'])
    model = model.cuda().eval()
       
    '''批量tif预测'''
    count = 0
    files = os.listdir(args.wsi_path)
    for eachfile in files:
        
        mask_path = args.mask_path+eachfile[:-4]+'.npy'
        mask = np.load(mask_path)
        if not os.path.exists(args.probs_map_path+eachfile[:-4]+'.npy'):
            if not args.eight_avg:
        
                dataloader = make_dataloader(
                    args, eachfile, mask_path, cfg, flip='NONE', rotate='NONE')
                    
                probs_map = get_probs_map(count, len(files), model, dataloader)
                
            else:
                probs_map = np.zeros(mask.shape)
        
                dataloader = make_dataloader(
                    args, eachfile, mask_path, cfg, flip='NONE', rotate='NONE')
                probs_map += get_probs_map(count, len(files), model, dataloader)
        
                dataloader = make_dataloader(
                    args, eachfile, mask_path, cfg, flip='NONE', rotate='ROTATE_90')
                probs_map += get_probs_map(count, len(files), model, dataloader)
        
                dataloader = make_dataloader(
                    args, eachfile, mask_path, cfg, flip='NONE', rotate='ROTATE_180')
                probs_map += get_probs_map(count, len(files), model, dataloader)
        
                dataloader = make_dataloader(
                    args, eachfile, mask_path, cfg, flip='NONE', rotate='ROTATE_270')
                probs_map += get_probs_map(count, len(files), model, dataloader)
        
                dataloader = make_dataloader(
                    args, eachfile, mask_path, cfg, flip='FLIP_LEFT_RIGHT', rotate='NONE')
                probs_map += get_probs_map(count, len(files), model, dataloader)
        
                dataloader = make_dataloader(
                    args, eachfile, mask_path, cfg, flip='FLIP_LEFT_RIGHT', rotate='ROTATE_90')
                probs_map += get_probs_map(count, len(files), model, dataloader)
        
                dataloader = make_dataloader(
                    args, eachfile, mask_path, cfg, flip='FLIP_LEFT_RIGHT', rotate='ROTATE_180')
                probs_map += get_probs_map(count, len(files), model, dataloader)
        
                dataloader = make_dataloader(
                    args, eachfile, mask_path, cfg, flip='FLIP_LEFT_RIGHT', rotate='ROTATE_270')
                probs_map += get_probs_map(count, len(files), model, dataloader)
        
                probs_map /= 8
        
            np.save(args.probs_map_path+eachfile[:-4], probs_map)        

        count += 1
                        
    '''单张tif预测'''        
 
#    mask = np.load(args.mask_path)
#    if not args.eight_avg:
#
#        dataloader = make_dataloader(
#            args, cfg, flip='NONE', rotate='NONE')
#            
#        probs_map = get_probs_map(model, dataloader)
#        
#    else:
#        probs_map = np.zeros(mask.shape)
#
#        dataloader = make_dataloader(
#            args, cfg, flip='NONE', rotate='NONE')
#        probs_map += get_probs_map(model, dataloader)
#
#        dataloader = make_dataloader(
#            args, cfg, flip='NONE', rotate='ROTATE_90')
#        probs_map += get_probs_map(model, dataloader)
#
#        dataloader = make_dataloader(
#            args, cfg, flip='NONE', rotate='ROTATE_180')
#        probs_map += get_probs_map(model, dataloader)
#
#        dataloader = make_dataloader(
#            args, cfg, flip='NONE', rotate='ROTATE_270')
#        probs_map += get_probs_map(model, dataloader)
#
#        dataloader = make_dataloader(
#            args, cfg, flip='FLIP_LEFT_RIGHT', rotate='NONE')
#        probs_map += get_probs_map(model, dataloader)
#
#        dataloader = make_dataloader(
#            args, cfg, flip='FLIP_LEFT_RIGHT', rotate='ROTATE_90')
#        probs_map += get_probs_map(model, dataloader)
#
#        dataloader = make_dataloader(
#            args, cfg, flip='FLIP_LEFT_RIGHT', rotate='ROTATE_180')
#        probs_map += get_probs_map(model, dataloader)
#
#        dataloader = make_dataloader(
#            args, cfg, flip='FLIP_LEFT_RIGHT', rotate='ROTATE_270')
#        probs_map += get_probs_map(model, dataloader)
#
#        probs_map /= 8
#
#    np.save(args.probs_map_path, probs_map)


def main():
    args = parser.parse_args()
    run(args)


if __name__ == '__main__':
    main()
